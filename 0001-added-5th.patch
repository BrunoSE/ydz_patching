From aebee2c62b991043ebfebe360b9afa47a08854e4 Mon Sep 17 00:00:00 2001
From: Bruno Stefoni <bruno.stefoni@cloudwerx.tech>
Date: Thu, 8 Feb 2024 06:55:56 -0500
Subject: [PATCH] added 5th

---
 train_network.py | 10 +++++-----
 1 file changed, 5 insertions(+), 5 deletions(-)

diff --git a/train_network.py b/train_network.py
index cd8ea8c..2db17c9 100644
--- a/train_network.py
+++ b/train_network.py
@@ -131,12 +131,12 @@ class NetworkTrainer:
     def all_reduce_network(self, accelerator, network):
         for param in network.parameters():
             if param.grad is not None:
-                print(f"Size of param.grad before reduction: {param.grad.size()}")
+                # print(f"Size of param.grad before reduction: {param.grad.size()}") # torch.Size([8, 640])
                 aux_param_grad = accelerator.reduce(param.grad, reduction="mean")
-                print(f"Size of aux after reduction: {aux_param_grad.size()}")
-                print(f"Number of Elements of aux after reduction: {aux_param_grad.numel()}")
-                print(f"Size of param.grad almost after reduction: {param.grad.size()}")
-                if aux_param_grad.numel() > 0:
+                # print(f"Size of aux after reduction: {aux_param_grad.size()}") # []
+                # print(f"Number of Elements of aux after reduction: {aux_param_grad.numel()}") # 1
+                # print(f"Size of param.grad almost after reduction: {param.grad.size()}") # torch.Size([8, 640])
+                if aux_param_grad.size() == param.grad.size():
                     param.grad = accelerator.reduce(param.grad, reduction="mean")
                     print(f"Size of param.grad after reduction: {param.grad.size()}")
 
-- 
2.39.3 (Apple Git-145)

